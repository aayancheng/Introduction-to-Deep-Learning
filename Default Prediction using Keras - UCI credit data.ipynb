{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI credit card data from [Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset)\n",
    "\n",
    "### Default Prediction using Keras. Original template from Wilson Kan. \n",
    "\n",
    "### Other references:\n",
    "\n",
    "deepcredit/default-prediction.ipynb\n",
    "\n",
    "[Ranking no. 1 on Kaggle for Predicting Consumer Debt Default ]( https://nycdatascience.com/blog/student-works/kaggle-predict-consumer-credit-default/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_columns', 55)\n",
    "data = pd.read_csv(\"defaultcreditcard.csv\", skiprows = 1)\n",
    "\n",
    "# display(data.describe())\n",
    "# display(data.head(5))\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create indicator variables for the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['MALE'] = np.where(data['SEX']==1, 1, 0)\n",
    "data['FEMALE'] = np.where(data['SEX']==2, 1, 0)\n",
    "data['MARRIED'] = np.where(data['MARRIAGE']==1, 1, 0)\n",
    "data['SINGLE'] = np.where(data['MARRIAGE']==2, 1, 0)\n",
    "data['STATUS_OTHER'] = np.where(np.logical_or(data['MARRIAGE']==3,data['MARRIAGE']==0), 1, 0)\n",
    "data['GRADUATE'] = np.where(data['EDUCATION']==1, 1, 0)\n",
    "data['UNIVERSITY'] = np.where(data['EDUCATION']==2, 1, 0)\n",
    "data['HIGHSCHOOL'] = np.where(data['EDUCATION']==3, 1, 0)\n",
    "data['EDU_OTHER'] = np.where(np.logical_or(data['EDUCATION']>=4,data['EDUCATION']==0), 1, 0)\n",
    "\n",
    "# Normalizing the data for age and others (making use of the map and lambda function to change the data)\n",
    "def my_normalize(s):\n",
    "    P90 = data[s].quantile(0.90)\n",
    "    data[s+\"_NORM\"] = data[s].map(lambda x: max(min(x / P90, 1), 0))\n",
    "def pay_normalize(s):\n",
    "    data[s+\"_NORM\"] = data[s].map(lambda x: x / 9)\n",
    "\n",
    "\n",
    "AGEMEAN = data['AGE'].mean()\n",
    "AGESTD = data['AGE'].std()\n",
    "\n",
    "header = list(data.columns.values)\n",
    "my_normalize(header[1])\n",
    "for s in header[12:24]:\n",
    "    my_normalize(s)\n",
    "for s in header[6:12]:\n",
    "    pay_normalize(s)\n",
    "data['AGE_NORM'] = data['AGE'].map(lambda x: (x - AGEMEAN) / AGESTD)\n",
    "\n",
    "\n",
    "# data.head(5)\n",
    "# data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form a new data set with the normalized variables and split it into 70% training, 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "header = list(data.columns.values)\n",
    "# use only the normalizeddata from column 25 and beyond \n",
    "model_data_full = data[header[24:]]\n",
    "\n",
    "header = list(model_data_full.columns.values)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(model_data_full[header[1:]], model_data_full[header[0]], test_size=0.3, random_state=2016)\n",
    "X_train, X_test = train_test_split(model_data_full[header[1:]], test_size=0.3, random_state=2016)\n",
    "# use a different method \"iloc\" to extract the sub dataframe so that it remains a n x 1 matrix instead of a series\n",
    "y_train, y_test = train_test_split(model_data_full.iloc[:,[0]], test_size=0.3, random_state=2016)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8eee2a049cfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# display(X_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m# display(y_train.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "# Convert the data type to numpy array from of data frame\n",
    "# display(type(X_train))\n",
    "# display(type(y_train))\n",
    "# display(X_train.shape)\n",
    "# display(y_train.shape)\n",
    "X_train = X_train.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "X_test = X_test.as_matrix()\n",
    "y_test = y_test.as_matrix()\n",
    "\n",
    "# np.ravel(y_train)\n",
    "display(type(X_train))\n",
    "display(type(y_train))\n",
    "display(type(X_test))\n",
    "display(type(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Keras using Tensorflow Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=29, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "              # metrics=['accuracy', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21000/21000 [==============================] - 1s 32us/step - loss: 0.4817 - acc: 0.7881\n",
      "Epoch 2/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4554 - acc: 0.8041\n",
      "Epoch 3/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4485 - acc: 0.8072\n",
      "Epoch 4/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4447 - acc: 0.8105\n",
      "Epoch 5/20\n",
      "21000/21000 [==============================] - 0s 12us/step - loss: 0.4423 - acc: 0.8113\n",
      "Epoch 6/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4403 - acc: 0.8127\n",
      "Epoch 7/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4388 - acc: 0.8143\n",
      "Epoch 8/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4370 - acc: 0.8164\n",
      "Epoch 9/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4349 - acc: 0.8161\n",
      "Epoch 10/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4338 - acc: 0.8182\n",
      "Epoch 11/20\n",
      "21000/21000 [==============================] - 0s 12us/step - loss: 0.4319 - acc: 0.8187\n",
      "Epoch 12/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4304 - acc: 0.8181\n",
      "Epoch 13/20\n",
      "21000/21000 [==============================] - 0s 16us/step - loss: 0.4291 - acc: 0.8200\n",
      "Epoch 14/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4284 - acc: 0.8188\n",
      "Epoch 15/20\n",
      "21000/21000 [==============================] - 0s 13us/step - loss: 0.4265 - acc: 0.8208\n",
      "Epoch 16/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4265 - acc: 0.8211\n",
      "Epoch 17/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4250 - acc: 0.8200\n",
      "Epoch 18/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4245 - acc: 0.8218\n",
      "Epoch 19/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4234 - acc: 0.8208\n",
      "Epoch 20/20\n",
      "21000/21000 [==============================] - 0s 14us/step - loss: 0.4229 - acc: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245b194c470>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 21us/step\n",
      "\n",
      "\n",
      "test accuracy: \n",
      "acc: 81.76%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose =1 )\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"test accuracy: \")\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "print(\"\\n\")      \n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[2], score[2]*100))\n",
    "# print(\"\\n\")      \n",
    "# print(\"%s: %.2f%%\" % (model.metrics_names[3], score[3]*100))\n",
    "\n",
    "# cvscores.append(scores[1] * 100)\n",
    "# print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "\n",
    "#How to do AUC measure under keras?\n",
    "# https://github.com/fchollet/keras/issues/832\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
